{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257f7e02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = pd.read_csv('./datasets/datasets/part3/204_x_train.csv')\n",
    "y_train  = pd.read_csv('./datasets/datasets/part3/204_y_train.csv')\n",
    "X_test = pd.read_csv('./datasets/datasets/part3/204_x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca6f2a5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train의 shape: (6599, 11)\n",
      "X_test의 shape: (4400, 11)\n",
      "y_train의 shape: (6599, 2)\n"
     ]
    }
   ],
   "source": [
    "print('X_train의 shape:', X_train.shape)\n",
    "print('X_test의 shape:', X_test.shape)\n",
    "print('y_train의 shape:', y_train.shape)\n",
    "\n",
    "### 아래의 셀에서 X_train + X_test = X_all로 만들 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a23a9862",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10999 entries, 0 to 4399\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   10999 non-null  int64 \n",
      " 1   Warehouse_block      10999 non-null  object\n",
      " 2   Mode_of_Shipment     10999 non-null  object\n",
      " 3   Customer_care_calls  10999 non-null  int64 \n",
      " 4   Customer_rating      10999 non-null  int64 \n",
      " 5   Cost_of_the_Product  10999 non-null  int64 \n",
      " 6   Prior_purchases      10999 non-null  int64 \n",
      " 7   Product_importance   10999 non-null  object\n",
      " 8   Gender               10999 non-null  object\n",
      " 9   Discount_offered     10999 non-null  int64 \n",
      " 10  Weight_in_gms        10999 non-null  int64 \n",
      "dtypes: int64(7), object(4)\n",
      "memory usage: 1.0+ MB\n",
      "\n",
      "문자형 자료의 컬럼:\n",
      " Index(['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## pd.concat 활용\n",
    "X_all = pd.concat([X_train, X_test])\n",
    "\n",
    "### 데이터 정보 확인\n",
    "X_all.info()\n",
    "\n",
    "### object인 자료의 컬럼들만 호출\n",
    "print('\\n문자형 자료의 컬럼:\\n', X_all.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2997e37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Warehouse_block', 'Mode_of_Shipment', 'Customer_care_calls',\n",
      "       'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases',\n",
      "       'Product_importance', 'Gender', 'Discount_offered', 'Weight_in_gms'],\n",
      "      dtype='object')\n",
      "\n",
      "Warehouse_block:\n",
      " F    2237\n",
      "A    1104\n",
      "B    1103\n",
      "C    1084\n",
      "D    1071\n",
      "Name: Warehouse_block, dtype: int64\n",
      "\n",
      "Mode_of_Shipment:\n",
      " Ship      4482\n",
      "Flight    1086\n",
      "Road      1031\n",
      "Name: Mode_of_Shipment, dtype: int64\n",
      "\n",
      "Customer_care_calls:\n",
      " 4    2177\n",
      "3    1911\n",
      "5    1391\n",
      "6     604\n",
      "2     370\n",
      "7     146\n",
      "Name: Customer_care_calls, dtype: int64\n",
      "\n",
      "Customer_rating:\n",
      " 3    1361\n",
      "1    1351\n",
      "5    1312\n",
      "4    1304\n",
      "2    1271\n",
      "Name: Customer_rating, dtype: int64\n",
      "\n",
      "Cost_of_the_Product:\n",
      " 257    68\n",
      "245    66\n",
      "260    64\n",
      "263    62\n",
      "254    60\n",
      "       ..\n",
      "107     3\n",
      "106     3\n",
      "303     3\n",
      "288     3\n",
      "119     2\n",
      "Name: Cost_of_the_Product, Length: 215, dtype: int64\n",
      "\n",
      "Prior_purchases:\n",
      " 3     2344\n",
      "2     1598\n",
      "4     1264\n",
      "5      794\n",
      "6      326\n",
      "10     108\n",
      "7       84\n",
      "8       81\n",
      "Name: Prior_purchases, dtype: int64\n",
      "\n",
      "Product_importance:\n",
      " low       3170\n",
      "medium    2854\n",
      "high       575\n",
      "Name: Product_importance, dtype: int64\n",
      "\n",
      "Gender:\n",
      " M    3303\n",
      "F    3296\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "Discount_offered:\n",
      " 2     527\n",
      "10    523\n",
      "6     519\n",
      "3     518\n",
      "4     499\n",
      "     ... \n",
      "32     21\n",
      "31     20\n",
      "50     20\n",
      "42     18\n",
      "30     17\n",
      "Name: Discount_offered, Length: 65, dtype: int64\n",
      "\n",
      "Weight_in_gms:\n",
      " 4883    10\n",
      "1817     9\n",
      "1145     8\n",
      "1247     8\n",
      "4172     8\n",
      "        ..\n",
      "1889     1\n",
      "2740     1\n",
      "3658     1\n",
      "2370     1\n",
      "3585     1\n",
      "Name: Weight_in_gms, Length: 3339, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1번풀이에서 정확도가 높지 않았으므로 우리는 X변수들을 \n",
    "# 재확인할 필요가 있습니다.\n",
    "\n",
    "print(X_train.columns)\n",
    "\n",
    "## ID -식별자라 제외\n",
    "\n",
    "# Warehouse_block - 몇개의 범주로만 구성되어 있으므로\n",
    "# 범주형 자료 - multi class로 봐도 무방\n",
    "print('\\nWarehouse_block:\\n', X_train.Warehouse_block.value_counts())\n",
    "\n",
    "# Mode_of_Shipment - 범주형\n",
    "# multi_class\n",
    "print('\\nMode_of_Shipment:\\n', X_train.Mode_of_Shipment.value_counts())\n",
    "\n",
    "# Mode_of_Shipment - 범주형\n",
    "# multi_class\n",
    "print('\\nCustomer_care_calls:\\n', X_train.Customer_care_calls.value_counts())\n",
    "\n",
    "# Customer_rating - 범주형\n",
    "# multi_class\n",
    "print('\\nCustomer_rating:\\n', X_train.Customer_rating.value_counts())\n",
    "\n",
    "# Cost_of_the_Product - 연속형\n",
    "# multi_class\n",
    "print('\\nCost_of_the_Product:\\n', X_train.Cost_of_the_Product.value_counts())\n",
    "\n",
    "# Prior_purchases - 범주형\n",
    "# multi_class\n",
    "print('\\nPrior_purchases:\\n', X_train.Prior_purchases.value_counts())\n",
    "\n",
    "# Product_importance - 범주형\n",
    "# multi_class\n",
    "print('\\nProduct_importance:\\n', X_train.Product_importance.value_counts())\n",
    "\n",
    "# Gender - 범주형\n",
    "# multi_class\n",
    "print('\\nGender:\\n', X_train.Gender.value_counts())\n",
    "\n",
    "# Discount_offered - 연속형\n",
    "# multi_class\n",
    "print('\\nDiscount_offered:\\n', X_train.Discount_offered.value_counts())\n",
    "\n",
    "# Weight_in_gms - 연속형\n",
    "# multi_class\n",
    "print('\\nWeight_in_gms:\\n', X_train.Weight_in_gms.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b15f312",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_all_contig = X_all[['Cost_of_the_Product','Discount_offered','Weight_in_gms']]\n",
    "\n",
    "## X_train과 X_all의 연속형 변수들만으로 구성한 후 split\n",
    "X_train_fin2 = X_all_contig[:6599]\n",
    "X_test_fin2 = X_all_contig[6599:]\n",
    "\n",
    "\n",
    "## 전처리 대상이 아니므로 y_train_fin을 카피하여 사용\n",
    "y_train_fin2 = y_train_fin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec91ea3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### 학습을 수행하기 위해 train_test_split을 활용한 val data를 생성\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain2, xval2, ytrain2, yval2 = train_test_split(X_train_fin2, y_train_fin2,\n",
    "                                             test_size=0.2,\n",
    "                                             stratify= y_train_fin2,\n",
    "                                             random_state=615)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78b2246a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf의 정확도: 0.6758\n",
      "rf_clf의 roc_auc점수: 0.6689\n",
      "gb_clf의 정확도: 0.6841\n",
      "gb_clf의 roc_auc점수: 0.7104\n"
     ]
    }
   ],
   "source": [
    "## 학습할 알고리즘 호출\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "### rf_clf를 적용\n",
    "rf_clf = RandomForestClassifier(random_state=615)\n",
    "rf_clf.fit(xtrain2,ytrain2)\n",
    "pred_rf = rf_clf.predict(xval2)\n",
    "\n",
    "accuracy_rf = accuracy_score(yval2,pred_rf)\n",
    "roc_auc_rf = roc_auc_score(yval2,pred_rf)\n",
    "\n",
    "## 평가지표 적용\n",
    "print('rf_clf의 정확도:', np.round(accuracy_rf,4))\n",
    "print('rf_clf의 roc_auc점수:', np.round(roc_auc_rf,4))\n",
    "\n",
    "### gb_clf를 적용\n",
    "gb_clf = GradientBoostingClassifier(random_state=615)\n",
    "gb_clf.fit(xtrain2,ytrain2)\n",
    "pred_gb = gb_clf.predict(xval2)\n",
    "\n",
    "accuracy_gb = accuracy_score(yval2,pred_gb)\n",
    "roc_auc_gb = roc_auc_score(yval2,pred_gb)\n",
    "\n",
    "## 평가지표 적용\n",
    "print('gb_clf의 정확도:', np.round(accuracy_gb,4))\n",
    "print('gb_clf의 roc_auc점수:', np.round(roc_auc_gb,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ab05e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### test1 번 종료를 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f7e48f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Warehouse_block</th>\n",
       "      <th>Mode_of_Shipment</th>\n",
       "      <th>Customer_care_calls</th>\n",
       "      <th>Customer_rating</th>\n",
       "      <th>Cost_of_the_Product</th>\n",
       "      <th>Prior_purchases</th>\n",
       "      <th>Product_importance</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Discount_offered</th>\n",
       "      <th>Weight_in_gms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9902</td>\n",
       "      <td>F</td>\n",
       "      <td>Ship</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>medium</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9501</td>\n",
       "      <td>A</td>\n",
       "      <td>Ship</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>4613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6111</td>\n",
       "      <td>A</td>\n",
       "      <td>Ship</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>264</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>5137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID Warehouse_block Mode_of_Shipment  Customer_care_calls  \\\n",
       "0  9902               F             Ship                    3   \n",
       "1  9501               A             Ship                    4   \n",
       "2  6111               A             Ship                    4   \n",
       "\n",
       "   Customer_rating  Cost_of_the_Product  Prior_purchases Product_importance  \\\n",
       "0                5                  214                2             medium   \n",
       "1                2                  201                3             medium   \n",
       "2                2                  264                3                low   \n",
       "\n",
       "  Gender  Discount_offered  Weight_in_gms  \n",
       "0      F                 6           4578  \n",
       "1      F                 4           4613  \n",
       "2      M                10           5137  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f1296ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### test2번 \n",
    "X_all_contig = X_all[['Customer_care_calls','Warehouse_block','Prior_purchases','Mode_of_Shipment','Cost_of_the_Product','Discount_offered','Weight_in_gms']]\n",
    "X_all_contig\n",
    "\n",
    "### 원-핫 인코딩을 적용해보자...\n",
    "X_all_oh_contig = pd.get_dummies(X_all_contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42e6284e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## X_train과 X_all의 연속형 변수들만으로 구성한 후 split\n",
    "X_train_fin3 = X_all_oh_contig[:6599]\n",
    "X_test_fin3 = X_all_oh_contig[6599:]\n",
    "\n",
    "\n",
    "## 전처리 대상이 아니므로 y_train_fin을 카피하여 사용\n",
    "y_train_fin3 = y_train_fin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0061ba07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### 학습을 수행하기 위해 train_test_split을 활용한 val data를 생성\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain3, xval3, ytrain3, yval3 = train_test_split(X_train_fin3, y_train_fin3,\n",
    "                                             test_size=0.2,\n",
    "                                             stratify= y_train_fin3,\n",
    "                                             random_state=615)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da5029ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf의 정확도: 0.6492\n",
      "rf_clf의 roc_auc점수: 0.6461\n",
      "gb_clf의 정확도: 0.6902\n",
      "gb_clf의 roc_auc점수: 0.7158\n"
     ]
    }
   ],
   "source": [
    "## 학습할 알고리즘 호출\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "### rf_clf를 적용\n",
    "rf_clf = RandomForestClassifier(random_state=615)\n",
    "rf_clf.fit(xtrain3,ytrain3)\n",
    "pred_rf = rf_clf.predict(xval3)\n",
    "\n",
    "accuracy_rf = accuracy_score(yval3,pred_rf)\n",
    "roc_auc_rf = roc_auc_score(yval3,pred_rf)\n",
    "\n",
    "## 평가지표 적용\n",
    "print('rf_clf의 정확도:', np.round(accuracy_rf,4))\n",
    "print('rf_clf의 roc_auc점수:', np.round(roc_auc_rf,4))\n",
    "\n",
    "### gb_clf를 적용\n",
    "gb_clf = GradientBoostingClassifier(random_state=615)\n",
    "gb_clf.fit(xtrain3,ytrain3)\n",
    "pred_gb = gb_clf.predict(xval3)\n",
    "\n",
    "accuracy_gb = accuracy_score(yval3,pred_gb)\n",
    "roc_auc_gb = roc_auc_score(yval3,pred_gb)\n",
    "\n",
    "## 평가지표 적용\n",
    "print('gb_clf의 정확도:', np.round(accuracy_gb,4))\n",
    "print('gb_clf의 roc_auc점수:', np.round(roc_auc_gb,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47207ccc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.648573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.627799\n",
      "[3]\tvalid_0's binary_logloss: 0.610208\n",
      "[4]\tvalid_0's binary_logloss: 0.595367\n",
      "[5]\tvalid_0's binary_logloss: 0.582682\n",
      "[6]\tvalid_0's binary_logloss: 0.571597\n",
      "[7]\tvalid_0's binary_logloss: 0.562433\n",
      "[8]\tvalid_0's binary_logloss: 0.554274\n",
      "[9]\tvalid_0's binary_logloss: 0.547962\n",
      "[10]\tvalid_0's binary_logloss: 0.542066\n",
      "[11]\tvalid_0's binary_logloss: 0.537026\n",
      "[12]\tvalid_0's binary_logloss: 0.5327\n",
      "[13]\tvalid_0's binary_logloss: 0.528678\n",
      "[14]\tvalid_0's binary_logloss: 0.525737\n",
      "[15]\tvalid_0's binary_logloss: 0.523255\n",
      "[16]\tvalid_0's binary_logloss: 0.519891\n",
      "[17]\tvalid_0's binary_logloss: 0.517181\n",
      "[18]\tvalid_0's binary_logloss: 0.51555\n",
      "[19]\tvalid_0's binary_logloss: 0.512902\n",
      "[20]\tvalid_0's binary_logloss: 0.511441\n",
      "[21]\tvalid_0's binary_logloss: 0.510107\n",
      "[22]\tvalid_0's binary_logloss: 0.508961\n",
      "[23]\tvalid_0's binary_logloss: 0.508415\n",
      "[24]\tvalid_0's binary_logloss: 0.507202\n",
      "[25]\tvalid_0's binary_logloss: 0.506635\n",
      "[26]\tvalid_0's binary_logloss: 0.506177\n",
      "[27]\tvalid_0's binary_logloss: 0.505512\n",
      "[28]\tvalid_0's binary_logloss: 0.50446\n",
      "[29]\tvalid_0's binary_logloss: 0.503485\n",
      "[30]\tvalid_0's binary_logloss: 0.503161\n",
      "[31]\tvalid_0's binary_logloss: 0.503433\n",
      "[32]\tvalid_0's binary_logloss: 0.502652\n",
      "[33]\tvalid_0's binary_logloss: 0.50237\n",
      "[34]\tvalid_0's binary_logloss: 0.502058\n",
      "[35]\tvalid_0's binary_logloss: 0.501765\n",
      "[36]\tvalid_0's binary_logloss: 0.501659\n",
      "[37]\tvalid_0's binary_logloss: 0.502004\n",
      "[38]\tvalid_0's binary_logloss: 0.501523\n",
      "[39]\tvalid_0's binary_logloss: 0.501116\n",
      "[40]\tvalid_0's binary_logloss: 0.500728\n",
      "[41]\tvalid_0's binary_logloss: 0.500383\n",
      "[42]\tvalid_0's binary_logloss: 0.500675\n",
      "[43]\tvalid_0's binary_logloss: 0.500682\n",
      "[44]\tvalid_0's binary_logloss: 0.500716\n",
      "[45]\tvalid_0's binary_logloss: 0.500567\n",
      "[46]\tvalid_0's binary_logloss: 0.500764\n",
      "[47]\tvalid_0's binary_logloss: 0.500134\n",
      "[48]\tvalid_0's binary_logloss: 0.500208\n",
      "[49]\tvalid_0's binary_logloss: 0.500527\n",
      "[50]\tvalid_0's binary_logloss: 0.50063\n",
      "[51]\tvalid_0's binary_logloss: 0.501119\n",
      "[52]\tvalid_0's binary_logloss: 0.501018\n",
      "[53]\tvalid_0's binary_logloss: 0.501264\n",
      "[54]\tvalid_0's binary_logloss: 0.500894\n",
      "[55]\tvalid_0's binary_logloss: 0.501269\n",
      "[56]\tvalid_0's binary_logloss: 0.502269\n",
      "[57]\tvalid_0's binary_logloss: 0.50287\n",
      "[58]\tvalid_0's binary_logloss: 0.502977\n",
      "[59]\tvalid_0's binary_logloss: 0.502976\n",
      "[60]\tvalid_0's binary_logloss: 0.503086\n",
      "[61]\tvalid_0's binary_logloss: 0.502535\n",
      "[62]\tvalid_0's binary_logloss: 0.502484\n",
      "[63]\tvalid_0's binary_logloss: 0.502405\n",
      "[64]\tvalid_0's binary_logloss: 0.502477\n",
      "[65]\tvalid_0's binary_logloss: 0.502826\n",
      "[66]\tvalid_0's binary_logloss: 0.503528\n",
      "[67]\tvalid_0's binary_logloss: 0.503407\n",
      "[68]\tvalid_0's binary_logloss: 0.503809\n",
      "[69]\tvalid_0's binary_logloss: 0.50372\n",
      "[70]\tvalid_0's binary_logloss: 0.504278\n",
      "[71]\tvalid_0's binary_logloss: 0.50446\n",
      "[72]\tvalid_0's binary_logloss: 0.504701\n",
      "[73]\tvalid_0's binary_logloss: 0.505018\n",
      "[74]\tvalid_0's binary_logloss: 0.504757\n",
      "[75]\tvalid_0's binary_logloss: 0.504851\n",
      "[76]\tvalid_0's binary_logloss: 0.504773\n",
      "[77]\tvalid_0's binary_logloss: 0.50505\n",
      "[78]\tvalid_0's binary_logloss: 0.505218\n",
      "[79]\tvalid_0's binary_logloss: 0.505633\n",
      "[80]\tvalid_0's binary_logloss: 0.50578\n",
      "[81]\tvalid_0's binary_logloss: 0.505512\n",
      "[82]\tvalid_0's binary_logloss: 0.505365\n",
      "[83]\tvalid_0's binary_logloss: 0.506065\n",
      "[84]\tvalid_0's binary_logloss: 0.50659\n",
      "[85]\tvalid_0's binary_logloss: 0.506716\n",
      "[86]\tvalid_0's binary_logloss: 0.507219\n",
      "[87]\tvalid_0's binary_logloss: 0.506805\n",
      "[88]\tvalid_0's binary_logloss: 0.506542\n",
      "[89]\tvalid_0's binary_logloss: 0.507092\n",
      "[90]\tvalid_0's binary_logloss: 0.507208\n",
      "[91]\tvalid_0's binary_logloss: 0.507554\n",
      "[92]\tvalid_0's binary_logloss: 0.508341\n",
      "[93]\tvalid_0's binary_logloss: 0.508828\n",
      "[94]\tvalid_0's binary_logloss: 0.508689\n",
      "[95]\tvalid_0's binary_logloss: 0.508585\n",
      "[96]\tvalid_0's binary_logloss: 0.509523\n",
      "[97]\tvalid_0's binary_logloss: 0.5096\n",
      "[98]\tvalid_0's binary_logloss: 0.510287\n",
      "[99]\tvalid_0's binary_logloss: 0.510581\n",
      "[100]\tvalid_0's binary_logloss: 0.510493\n",
      "[101]\tvalid_0's binary_logloss: 0.510397\n",
      "[102]\tvalid_0's binary_logloss: 0.510939\n",
      "[103]\tvalid_0's binary_logloss: 0.510506\n",
      "[104]\tvalid_0's binary_logloss: 0.510778\n",
      "[105]\tvalid_0's binary_logloss: 0.510989\n",
      "[106]\tvalid_0's binary_logloss: 0.510843\n",
      "[107]\tvalid_0's binary_logloss: 0.511014\n",
      "[108]\tvalid_0's binary_logloss: 0.511272\n",
      "[109]\tvalid_0's binary_logloss: 0.511754\n",
      "[110]\tvalid_0's binary_logloss: 0.511984\n",
      "[111]\tvalid_0's binary_logloss: 0.51207\n",
      "[112]\tvalid_0's binary_logloss: 0.51272\n",
      "[113]\tvalid_0's binary_logloss: 0.513022\n",
      "[114]\tvalid_0's binary_logloss: 0.512989\n",
      "[115]\tvalid_0's binary_logloss: 0.513202\n",
      "[116]\tvalid_0's binary_logloss: 0.512948\n",
      "[117]\tvalid_0's binary_logloss: 0.512952\n",
      "[118]\tvalid_0's binary_logloss: 0.513287\n",
      "[119]\tvalid_0's binary_logloss: 0.51368\n",
      "[120]\tvalid_0's binary_logloss: 0.514196\n",
      "[121]\tvalid_0's binary_logloss: 0.514032\n",
      "[122]\tvalid_0's binary_logloss: 0.514452\n",
      "[123]\tvalid_0's binary_logloss: 0.514745\n",
      "[124]\tvalid_0's binary_logloss: 0.514692\n",
      "[125]\tvalid_0's binary_logloss: 0.514847\n",
      "[126]\tvalid_0's binary_logloss: 0.515199\n",
      "[127]\tvalid_0's binary_logloss: 0.515167\n",
      "[128]\tvalid_0's binary_logloss: 0.515456\n",
      "[129]\tvalid_0's binary_logloss: 0.515952\n",
      "[130]\tvalid_0's binary_logloss: 0.515877\n",
      "[131]\tvalid_0's binary_logloss: 0.515776\n",
      "[132]\tvalid_0's binary_logloss: 0.51572\n",
      "[133]\tvalid_0's binary_logloss: 0.515669\n",
      "[134]\tvalid_0's binary_logloss: 0.515949\n",
      "[135]\tvalid_0's binary_logloss: 0.516035\n",
      "[136]\tvalid_0's binary_logloss: 0.516065\n",
      "[137]\tvalid_0's binary_logloss: 0.51625\n",
      "[138]\tvalid_0's binary_logloss: 0.516451\n",
      "[139]\tvalid_0's binary_logloss: 0.517259\n",
      "[140]\tvalid_0's binary_logloss: 0.51734\n",
      "[141]\tvalid_0's binary_logloss: 0.517336\n",
      "[142]\tvalid_0's binary_logloss: 0.517753\n",
      "[143]\tvalid_0's binary_logloss: 0.517804\n",
      "[144]\tvalid_0's binary_logloss: 0.518184\n",
      "[145]\tvalid_0's binary_logloss: 0.518045\n",
      "[146]\tvalid_0's binary_logloss: 0.518072\n",
      "[147]\tvalid_0's binary_logloss: 0.518043\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's binary_logloss: 0.500134\n",
      "lgbm_clf의 정확도: 0.6712\n",
      "lgbm_clf의 roc_auc_점수: 0.6865\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators = 400)\n",
    "\n",
    "# LightGBM early_stopping_rounds 확인\n",
    "evals3 = [(xval3,yval3)]\n",
    "lgbm_wrapper.fit(xtrain3,ytrain3,early_stopping_rounds=100,\n",
    "                eval_metric='logloss',\n",
    "                eval_set = evals3,\n",
    "                verbose=True)\n",
    "\n",
    "pred_lgbm3 = lgbm_wrapper.predict(xval3)\n",
    "\n",
    "accuracy_lgbm = accuracy_score(yval3,pred_lgbm3)\n",
    "roc_auc_lgbm = roc_auc_score(yval3,pred_lgbm3)\n",
    "\n",
    "print('lgbm_clf의 정확도:', np.round(accuracy_lgbm,4))\n",
    "print('lgbm_clf의 roc_auc_점수:', np.round(roc_auc_lgbm,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b20ba72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## test_coding에서도 즉, one-hot 인코딩을 적용해보아도 더 높은\n",
    "## accuracy 및 roc_auc 점수를 devoloping(개선)시키지 못하였습니다.\n",
    "\n",
    "# 혹시라도 여러분들께서 더 좋은 점수가 나오신다면\n",
    "# 같이 공유 부탁드립니다.\n",
    "\n",
    "# 오전 수업 수고많으셨습니다 ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71acc46d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.2        ... 0.         0.078125   0.52257122]\n",
      " [0.         1.         0.4        ... 0.         0.046875   0.52768444]\n",
      " [0.         1.         0.4        ... 1.         0.140625   0.60423667]\n",
      " ...\n",
      " [0.75       0.         0.2        ... 0.         0.140625   0.58392988]\n",
      " [0.25       1.         0.2        ... 1.         0.140625   0.48794741]\n",
      " [0.25       0.5        0.2        ... 0.         0.125      0.69291454]]\n"
     ]
    }
   ],
   "source": [
    "# #### Label Encoding시 분석 알고리즘\n",
    "\n",
    "# ### 불필요속성\n",
    "\n",
    "# X_all_drop = X_all.drop(['ID'], axis=1)\n",
    "\n",
    "\n",
    "# ### MinMaxScaler를 적용해본다.\n",
    "# ### MinMaxScaling을 적용하는 이유는 간단한데,\n",
    "# ### 데이터들의 정규성 가정을 우리가 확신하지 못해서입니다.\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# mm_scaler = MinMaxScaler()\n",
    "# result_ndarray = mm_scaler.fit_transform(X_all_drop)\n",
    "\n",
    "# print(result_ndarray)\n",
    "\n",
    "# ## 전처리된 X값들과 y값을 재정의\n",
    "# X_train_fin = result_ndarray[:6599]\n",
    "# X_test_fin = result_ndarray[6599:]\n",
    "# y_train_fin = y_train['Reached.on.Time_Y.N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c409072",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ### 학습을 수행하기 위해 train_test_split을 활용한 val data를 생성\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xtrain, xval, ytrain, yval = train_test_split(X_train_fin, y_train_fin,\n",
    "#                                              test_size=0.2,\n",
    "#                                              stratify=y_train_fin,\n",
    "#                                              random_state=615)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97350186",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf의 정확도: 0.6598\n",
      "rf_clf의 roc_auc점수: 0.6598\n",
      "gb_clf의 정확도: 0.6924\n",
      "gb_clf의 roc_auc점수: 0.7183\n"
     ]
    }
   ],
   "source": [
    "# ## 학습할 알고리즘 호출\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# ### rf_clf를 적용\n",
    "# rf_clf = RandomForestClassifier(random_state=615)\n",
    "# rf_clf.fit(xtrain,ytrain)\n",
    "# pred_rf = rf_clf.predict(xval)\n",
    "\n",
    "# accuracy_rf = accuracy_score(yval,pred_rf)\n",
    "# roc_auc_rf = roc_auc_score(yval,pred_rf)\n",
    "\n",
    "# ## 평가지표 적용\n",
    "# print('rf_clf의 정확도:', np.round(accuracy_rf,4))\n",
    "# print('rf_clf의 roc_auc점수:', np.round(roc_auc_rf,4))\n",
    "\n",
    "# ### gb_clf를 적용\n",
    "# gb_clf = GradientBoostingClassifier(random_state=615)\n",
    "# gb_clf.fit(xtrain,ytrain)\n",
    "# pred_gb = gb_clf.predict(xval)\n",
    "\n",
    "# accuracy_gb = accuracy_score(yval,pred_gb)\n",
    "# roc_auc_gb = roc_auc_score(yval,pred_gb)\n",
    "\n",
    "# ## 평가지표 적용\n",
    "# print('gb_clf의 정확도:', np.round(accuracy_gb,4))\n",
    "# print('gb_clf의 roc_auc점수:', np.round(roc_auc_gb,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f4a63d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm_clf의 정확도: 0.6811\n",
      "lgbm_clf의 roc_auc점수: 0.6968\n"
     ]
    }
   ],
   "source": [
    "# ### lightgbm 적용\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# # 400개의 분류기를 생성\n",
    "# lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# evals = [(xval,yval)]\n",
    "\n",
    "# lgbm_wrapper.fit(xtrain,ytrain, early_stopping_rounds=100,\n",
    "#                 eval_metric='logloss',\n",
    "#                 eval_set = evals,\n",
    "#                 verbose = False) # 미리 정확도가 아닌 'logloss'지표로\n",
    "#                                 # 알고리즘의 over-fitting방지 및\n",
    "#                                 # 정확도를 살펴본다.\n",
    "\n",
    "# pred_lgbm = lgbm_wrapper.predict(xval) # xval을 넣었을때 예상되는 y값\n",
    "\n",
    "# accuracy_lgbm = accuracy_score(yval,pred_lgbm)\n",
    "# roc_auc_lgbm = roc_auc_score(yval,pred_lgbm)\n",
    "\n",
    "# ## 평가지표 적용\n",
    "# print('lgbm_clf의 정확도:', np.round(accuracy_lgbm,4))\n",
    "# print('lgbm_clf의 roc_auc점수:', np.round(roc_auc_lgbm,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd84fb85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ## 최종결과 제출 코드 ##\n",
    "\n",
    "# final_model = gb_clf.fit(X_train_fin, y_train_fin)\n",
    "# y_pred = final_model.predict(X_test_fin)\n",
    "\n",
    "# ### 제출파일을 생성\n",
    "# submit_df = pd.DataFrame({'y_pred':y_pred}).reset_index()\n",
    "# submit_df\n",
    "\n",
    "# submit_df.to_csv('./220615.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3b49a6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# end of file -2 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}