{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "344bdf58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\user\\\\1P\\\\0614'"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "671eb0f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_test = pd.read_csv('.//304_x_test.csv') # X_test  \n",
    "X_train = pd.read_csv('.//304_x_train.csv')  # X_train \n",
    "y_train = pd.read_csv('.//304_y_train.csv')  # y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2cc38399",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train의 shape: (1490, 9)\n",
      "y_train의 shape: (1490, 2)\n",
      "X_test의 shape: (497, 9)\n"
     ]
    }
   ],
   "source": [
    "print('X_train의 shape:',X_train.shape)\n",
    "print('y_train의 shape:',y_train.shape)\n",
    "print('X_test의 shape:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4864bb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1987 entries, 0 to 496\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   1987 non-null   int64 \n",
      " 1   Age                  1987 non-null   int64 \n",
      " 2   Employment Type      1987 non-null   object\n",
      " 3   GraduateOrNot        1987 non-null   object\n",
      " 4   AnnualIncome         1987 non-null   int64 \n",
      " 5   FamilyMembers        1987 non-null   int64 \n",
      " 6   ChronicDiseases      1987 non-null   int64 \n",
      " 7   FrequentFlyer        1987 non-null   object\n",
      " 8   EverTravelledAbroad  1987 non-null   object\n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 155.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                ID          Age  AnnualIncome  FamilyMembers  ChronicDiseases\ncount  1987.000000  1987.000000  1.987000e+03    1987.000000      1987.000000\nmean    993.000000    29.650226  9.327630e+05       4.752894         0.277806\nstd     573.741812     2.913308  3.768557e+05       1.609650         0.448030\nmin       0.000000    25.000000  3.000000e+05       2.000000         0.000000\n25%     496.500000    28.000000  6.000000e+05       4.000000         0.000000\n50%     993.000000    29.000000  9.000000e+05       5.000000         0.000000\n75%    1489.500000    32.000000  1.250000e+06       6.000000         1.000000\nmax    1986.000000    35.000000  1.800000e+06       9.000000         1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>AnnualIncome</th>\n      <th>FamilyMembers</th>\n      <th>ChronicDiseases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1987.000000</td>\n      <td>1987.000000</td>\n      <td>1.987000e+03</td>\n      <td>1987.000000</td>\n      <td>1987.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>993.000000</td>\n      <td>29.650226</td>\n      <td>9.327630e+05</td>\n      <td>4.752894</td>\n      <td>0.277806</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>573.741812</td>\n      <td>2.913308</td>\n      <td>3.768557e+05</td>\n      <td>1.609650</td>\n      <td>0.448030</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>25.000000</td>\n      <td>3.000000e+05</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>496.500000</td>\n      <td>28.000000</td>\n      <td>6.000000e+05</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>993.000000</td>\n      <td>29.000000</td>\n      <td>9.000000e+05</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1489.500000</td>\n      <td>32.000000</td>\n      <td>1.250000e+06</td>\n      <td>6.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1986.000000</td>\n      <td>35.000000</td>\n      <td>1.800000e+06</td>\n      <td>9.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 데이터의 기술통계량, 요약, 정보확인\n",
    "### X_train과 X_test를 결합... :: pd.concat([X_train,X_test])\n",
    "\n",
    "X_all = pd.concat([X_train,X_test])\n",
    "\n",
    "## 데이터 정보확인\n",
    "X_all.info()\n",
    "\n",
    "## 데이터의 기술통계량\n",
    "X_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 2, 3, 3, 3], dtype=int64)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = ['TV','냉장고','전자레인지','컴퓨터','컴퓨터','컴퓨터']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(items)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "dict1 = {'big_data':['ysp','sh','sk'],\n",
    "        'python':['dy','luis','fonsi']}\n",
    "\n",
    "test_df = pd.DataFrame(dict1)\n",
    "test_df\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "test_df['python'] = le.fit_transform(test_df['python'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "  big_data  python\n0      ysp       0\n1       sh       2\n2       sk       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>big_data</th>\n      <th>python</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ysp</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sh</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sk</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d51f310b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### 데이터 전처리 - 결측값 X, 문자 -> 숫자, 불필요컬럼제거 \n",
    "### 문자를 숫자로 변환\n",
    "# select_dtypes 함수로 object데이터와 컬럼 추출\n",
    "X_all.select_dtypes(include='object').columns \n",
    "\n",
    "# 문자열 컬럼들을 list로 할당 \n",
    "obj_ftrs = ['Employment Type', 'GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad']\n",
    "obj_ftrs\n",
    "\n",
    "# Label Encoding을 적용 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder() # le로 객체화 \n",
    "\n",
    "for ftr in obj_ftrs:\n",
    "    X_all[ftr] = le.fit_transform(X_all[ftr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2967912b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1987, 8)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## X_all 즉, X_train과 X_test에 해당하는 문자 -> 숫자 \n",
    "X_all.head(3)\n",
    "\n",
    "\n",
    "## 불필요속성 제거\n",
    "X_all_drop = X_all.drop(['ID'],axis=1)\n",
    "\n",
    "\n",
    "### MinMaxScaling :: 데이터의 분포가 정규분포(즉, 가우시안 분포)가 아니므로..\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler() # 객체화\n",
    "X_all_fin = mm_scaler.fit_transform(X_all_drop)\n",
    "X_all_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_fin의 shape: (1490, 8)\n",
      "X_test_fin의 shape: (497, 8)\n",
      "y_train_fin의 shape: (1490, 1)\n"
     ]
    }
   ],
   "source": [
    "### 다시금 X_train 과 X_test로 분리\n",
    "X_train_fin = X_all_fin[:1490]\n",
    "X_train_fin.shape\n",
    "X_test_fin = X_all_fin[1490:]\n",
    "\n",
    "print('X_train_fin의 shape:', X_train_fin.shape)\n",
    "print('X_test_fin의 shape:', X_test_fin.shape)\n",
    "\n",
    "# y_train_fin = y_train.copy()\n",
    "y_train_fin = y_train.drop(['ID'], axis= 1)\n",
    "print('y_train_fin의 shape:', y_train_fin.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0과 1의 비율 0.3624\n"
     ]
    }
   ],
   "source": [
    "data_ratio1 = y_train_fin.TravelInsurance.value_counts()\n",
    "total_cnt = data_ratio1[0] + data_ratio1[1]  # 전체의 y 개수\n",
    "insu_cnt = data_ratio1[1]\n",
    "\n",
    "print('0과 1의 비율', np.round(insu_cnt / total_cnt, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "### 데이터 분할 :: train_test_split :: X_train 및 y_train을 val로 쪼개는\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xval, ytrain, yval = train_test_split(X_train_fin, y_train_fin, test_size=0.25, stratify=y_train_fin ,random_state=614)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35452103849597133\n",
      "0.32505643340857787\n"
     ]
    }
   ],
   "source": [
    "### train_test_split의 stratify의 파라미터를 조절하여\n",
    "## 최대한 데이터의 분포를 train의 갑과 동이랗게 만들어줍니다\n",
    "\n",
    "ytrain.value_counts()\n",
    "yval.value_counts()\n",
    "\n",
    "print(396/(721+396))\n",
    "print(144/(299+144))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "### 알고리즘 적용 - dt_clf, rf_clf, gb_clf, ada_clf ___ 트리계열\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_clf 정확도: 0.7292225201072386\n",
      "dt_clf roc_auc: 0.7076719576719577\n"
     ]
    }
   ],
   "source": [
    "# dt_clf로 객체화\n",
    "dt_clf = DecisionTreeClassifier(random_state=614)\n",
    "dt_clf.fit(xtrain, ytrain) # 여기에 들어가는 train은 x와 y를 분할한 데이터입니다\n",
    "dt_clf.predict(xval)\n",
    "pred_dt = dt_clf.predict(xval)\n",
    "\n",
    "print('dt_clf 정확도:', accuracy_score(yval, pred_dt))\n",
    "print('dt_clf roc_auc:', roc_auc_score(yval, pred_dt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf 정확도: 0.806970509383378\n",
      "rf_clf roc_auc: 0.7910364145658264\n"
     ]
    }
   ],
   "source": [
    "# rf_clf로 객체화\n",
    "rf_clf = RandomForestClassifier(random_state=614)\n",
    "rf_clf.fit(xtrain, ytrain) # 여기에 들어가는 train은 x와 y를 분할한 데이터입니다\n",
    "rf_clf.predict(xval)\n",
    "pred_rf = rf_clf.predict(xval)\n",
    "\n",
    "print('rf_clf 정확도:', accuracy_score(yval, pred_rf))\n",
    "print('rf_clf roc_auc:', roc_auc_score(yval, pred_rf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb_clf 정확도: 0.8525469168900804\n",
      "gb_clf roc_auc: 0.8123249299719887\n"
     ]
    }
   ],
   "source": [
    "# gb_clf로 객체화\n",
    "gb_clf = GradientBoostingClassifier(random_state=614)\n",
    "gb_clf.fit(xtrain, ytrain) # 여기에 들어가는 train은 x와 y를 분할한 데이터입니다\n",
    "gb_clf.predict(xval)\n",
    "pred_gb = gb_clf.predict(xval)\n",
    "\n",
    "print('gb_clf 정확도:', accuracy_score(yval, pred_gb))\n",
    "print('gb_clf roc_auc:', roc_auc_score(yval, pred_gb))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_clf 정확도: 0.8525469168900804\n",
      "ada_clf roc_auc: 0.8123249299719887\n"
     ]
    }
   ],
   "source": [
    "# ada_clf로 객체화\n",
    "ada_clf = AdaBoostClassifier(random_state=614)\n",
    "ada_clf.fit(xtrain, ytrain) # 여기에 들어가는 train은 x와 y를 분할한 데이터입니다\n",
    "ada_clf.predict(xval)\n",
    "pred_ada = gb_clf.predict(xval)\n",
    "\n",
    "print('ada_clf 정확도:', accuracy_score(yval, pred_ada))\n",
    "print('ada_clf roc_auc:', roc_auc_score(yval, pred_ada))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "### 최종 제출 모델\n",
    "# 엄밀히 xtrain + xval = 전체_X_train\n",
    "# 엄밀히 ytrain + yval = 전체_y_train\n",
    "#  \"\"   X_test_fin\n",
    "\n",
    "final_model = GradientBoostingClassifier().fit(X_train_fin, y_train_fin)\n",
    "y_pred = final_model.predict_proba(X_test_fin)  # 예측확률을 뽑음\n",
    "y_pred = y_pred[:, 1] # 그 예측 확률 중 class 1인 녀석을 다시 할당"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "     y_pred\n0    0.1718\n1    0.9761\n2    0.2152\n3    0.2825\n4    0.9547\n..      ...\n492  0.1680\n493  0.0112\n494  0.1641\n495  0.3305\n496  0.1448\n\n[497 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.1718</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.9761</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.2152</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.2825</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.9547</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>492</th>\n      <td>0.1680</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>0.0112</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>0.1641</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>0.3305</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0.1448</td>\n    </tr>\n  </tbody>\n</table>\n<p>497 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### csv 제출을 위한 작업\n",
    "pd.DataFrame({'y_pred':np.round(y_pred, 4)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "### csv 제출\n",
    "result = pd.DataFrame({'y_pred':np.round(y_pred, 4)})\n",
    "result.to_csv('./220614.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc_sc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def get_index(y_test, pred):\n",
    "    accuracy = acc_sc(y_test, pred)\n",
    "    p_score = precision_score(y_test, pred)\n",
    "    r_score = recall_score(y_test, pred)\n",
    "    f_score = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "\n",
    "    print('정확도 : {0:.4f}, 정밀도 : {1:.4f}, Recall:{2:.4f}, F1:{3:.4f}, roc:{4: .4f}'.format(accuracy, p_score, r_score, f_score, roc_auc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.60895\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.572484\n",
      "[3]\tvalid_0's binary_logloss: 0.544049\n",
      "[4]\tvalid_0's binary_logloss: 0.520374\n",
      "[5]\tvalid_0's binary_logloss: 0.501601\n",
      "[6]\tvalid_0's binary_logloss: 0.484984\n",
      "[7]\tvalid_0's binary_logloss: 0.471206\n",
      "[8]\tvalid_0's binary_logloss: 0.459632\n",
      "[9]\tvalid_0's binary_logloss: 0.449782\n",
      "[10]\tvalid_0's binary_logloss: 0.441421\n",
      "[11]\tvalid_0's binary_logloss: 0.435402\n",
      "[12]\tvalid_0's binary_logloss: 0.429517\n",
      "[13]\tvalid_0's binary_logloss: 0.423278\n",
      "[14]\tvalid_0's binary_logloss: 0.418881\n",
      "[15]\tvalid_0's binary_logloss: 0.415444\n",
      "[16]\tvalid_0's binary_logloss: 0.411771\n",
      "[17]\tvalid_0's binary_logloss: 0.408686\n",
      "[18]\tvalid_0's binary_logloss: 0.40638\n",
      "[19]\tvalid_0's binary_logloss: 0.405613\n",
      "[20]\tvalid_0's binary_logloss: 0.403641\n",
      "[21]\tvalid_0's binary_logloss: 0.402275\n",
      "[22]\tvalid_0's binary_logloss: 0.400689\n",
      "[23]\tvalid_0's binary_logloss: 0.398217\n",
      "[24]\tvalid_0's binary_logloss: 0.397013\n",
      "[25]\tvalid_0's binary_logloss: 0.395217\n",
      "[26]\tvalid_0's binary_logloss: 0.394597\n",
      "[27]\tvalid_0's binary_logloss: 0.393869\n",
      "[28]\tvalid_0's binary_logloss: 0.395331\n",
      "[29]\tvalid_0's binary_logloss: 0.395085\n",
      "[30]\tvalid_0's binary_logloss: 0.395828\n",
      "[31]\tvalid_0's binary_logloss: 0.395525\n",
      "[32]\tvalid_0's binary_logloss: 0.396198\n",
      "[33]\tvalid_0's binary_logloss: 0.396983\n",
      "[34]\tvalid_0's binary_logloss: 0.39708\n",
      "[35]\tvalid_0's binary_logloss: 0.397461\n",
      "[36]\tvalid_0's binary_logloss: 0.398245\n",
      "[37]\tvalid_0's binary_logloss: 0.399626\n",
      "[38]\tvalid_0's binary_logloss: 0.399999\n",
      "[39]\tvalid_0's binary_logloss: 0.400727\n",
      "[40]\tvalid_0's binary_logloss: 0.400671\n",
      "[41]\tvalid_0's binary_logloss: 0.401106\n",
      "[42]\tvalid_0's binary_logloss: 0.400929\n",
      "[43]\tvalid_0's binary_logloss: 0.401409\n",
      "[44]\tvalid_0's binary_logloss: 0.400382\n",
      "[45]\tvalid_0's binary_logloss: 0.401883\n",
      "[46]\tvalid_0's binary_logloss: 0.402107\n",
      "[47]\tvalid_0's binary_logloss: 0.402064\n",
      "[48]\tvalid_0's binary_logloss: 0.403247\n",
      "[49]\tvalid_0's binary_logloss: 0.402544\n",
      "[50]\tvalid_0's binary_logloss: 0.403631\n",
      "[51]\tvalid_0's binary_logloss: 0.404841\n",
      "[52]\tvalid_0's binary_logloss: 0.405913\n",
      "[53]\tvalid_0's binary_logloss: 0.405441\n",
      "[54]\tvalid_0's binary_logloss: 0.406046\n",
      "[55]\tvalid_0's binary_logloss: 0.405997\n",
      "[56]\tvalid_0's binary_logloss: 0.406393\n",
      "[57]\tvalid_0's binary_logloss: 0.406801\n",
      "[58]\tvalid_0's binary_logloss: 0.407498\n",
      "[59]\tvalid_0's binary_logloss: 0.408964\n",
      "[60]\tvalid_0's binary_logloss: 0.409838\n",
      "[61]\tvalid_0's binary_logloss: 0.410928\n",
      "[62]\tvalid_0's binary_logloss: 0.411704\n",
      "[63]\tvalid_0's binary_logloss: 0.411995\n",
      "[64]\tvalid_0's binary_logloss: 0.414013\n",
      "[65]\tvalid_0's binary_logloss: 0.412873\n",
      "[66]\tvalid_0's binary_logloss: 0.413393\n",
      "[67]\tvalid_0's binary_logloss: 0.414116\n",
      "[68]\tvalid_0's binary_logloss: 0.415416\n",
      "[69]\tvalid_0's binary_logloss: 0.415467\n",
      "[70]\tvalid_0's binary_logloss: 0.415473\n",
      "[71]\tvalid_0's binary_logloss: 0.416565\n",
      "[72]\tvalid_0's binary_logloss: 0.417213\n",
      "[73]\tvalid_0's binary_logloss: 0.418919\n",
      "[74]\tvalid_0's binary_logloss: 0.419421\n",
      "[75]\tvalid_0's binary_logloss: 0.419636\n",
      "[76]\tvalid_0's binary_logloss: 0.419492\n",
      "[77]\tvalid_0's binary_logloss: 0.420522\n",
      "[78]\tvalid_0's binary_logloss: 0.421185\n",
      "[79]\tvalid_0's binary_logloss: 0.422347\n",
      "[80]\tvalid_0's binary_logloss: 0.422293\n",
      "[81]\tvalid_0's binary_logloss: 0.423011\n",
      "[82]\tvalid_0's binary_logloss: 0.422392\n",
      "[83]\tvalid_0's binary_logloss: 0.422942\n",
      "[84]\tvalid_0's binary_logloss: 0.424551\n",
      "[85]\tvalid_0's binary_logloss: 0.426167\n",
      "[86]\tvalid_0's binary_logloss: 0.426001\n",
      "[87]\tvalid_0's binary_logloss: 0.425903\n",
      "[88]\tvalid_0's binary_logloss: 0.427082\n",
      "[89]\tvalid_0's binary_logloss: 0.428779\n",
      "[90]\tvalid_0's binary_logloss: 0.4298\n",
      "[91]\tvalid_0's binary_logloss: 0.430271\n",
      "[92]\tvalid_0's binary_logloss: 0.431812\n",
      "[93]\tvalid_0's binary_logloss: 0.432357\n",
      "[94]\tvalid_0's binary_logloss: 0.433813\n",
      "[95]\tvalid_0's binary_logloss: 0.433458\n",
      "[96]\tvalid_0's binary_logloss: 0.434524\n",
      "[97]\tvalid_0's binary_logloss: 0.435349\n",
      "[98]\tvalid_0's binary_logloss: 0.436023\n",
      "[99]\tvalid_0's binary_logloss: 0.436881\n",
      "[100]\tvalid_0's binary_logloss: 0.43665\n",
      "[101]\tvalid_0's binary_logloss: 0.437019\n",
      "[102]\tvalid_0's binary_logloss: 0.43878\n",
      "[103]\tvalid_0's binary_logloss: 0.439\n",
      "[104]\tvalid_0's binary_logloss: 0.439674\n",
      "[105]\tvalid_0's binary_logloss: 0.439116\n",
      "[106]\tvalid_0's binary_logloss: 0.440584\n",
      "[107]\tvalid_0's binary_logloss: 0.441604\n",
      "[108]\tvalid_0's binary_logloss: 0.442406\n",
      "[109]\tvalid_0's binary_logloss: 0.443036\n",
      "[110]\tvalid_0's binary_logloss: 0.44433\n",
      "[111]\tvalid_0's binary_logloss: 0.444282\n",
      "[112]\tvalid_0's binary_logloss: 0.44519\n",
      "[113]\tvalid_0's binary_logloss: 0.446193\n",
      "[114]\tvalid_0's binary_logloss: 0.447783\n",
      "[115]\tvalid_0's binary_logloss: 0.449242\n",
      "[116]\tvalid_0's binary_logloss: 0.450098\n",
      "[117]\tvalid_0's binary_logloss: 0.451097\n",
      "[118]\tvalid_0's binary_logloss: 0.452087\n",
      "[119]\tvalid_0's binary_logloss: 0.452434\n",
      "[120]\tvalid_0's binary_logloss: 0.452714\n",
      "[121]\tvalid_0's binary_logloss: 0.45373\n",
      "[122]\tvalid_0's binary_logloss: 0.4553\n",
      "[123]\tvalid_0's binary_logloss: 0.455763\n",
      "[124]\tvalid_0's binary_logloss: 0.456091\n",
      "[125]\tvalid_0's binary_logloss: 0.456665\n",
      "[126]\tvalid_0's binary_logloss: 0.4577\n",
      "[127]\tvalid_0's binary_logloss: 0.457731\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's binary_logloss: 0.393869\n"
     ]
    },
    {
     "data": {
      "text/plain": "LGBMClassifier(n_estimators=400)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(n_estimators=400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(n_estimators=400)</pre></div></div></div></div></div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 새로운 알고리즘인 LightGBM을 사용해본다.\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# n_estimators=400그루를 설정\n",
    "# 일반적인 알고리즘의 객체화\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# LightGBM early_stopping_rounds 확인\n",
    "evals = [(xval, yval)]\n",
    "\n",
    "## LGBM 학습 및 예측\n",
    "lgbm_wrapper.fit(xtrain, ytrain, early_stopping_rounds=100, eval_metric='logloss', eval_set=evals,\n",
    "                 verbose=True)\n",
    "# verbose True -> 값 보임, verbose False -> 값 안보임"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.8499, 정밀도 : 0.8692, Recall:0.6889, F1:0.7686, roc: 0.8150\n"
     ]
    }
   ],
   "source": [
    "pred_lgbm = lgbm_wrapper.predict(xval)\n",
    "\n",
    "get_index(yval, pred_lgbm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# end of file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}